{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating Columns That Have Very Few Values\n",
    "### There were columns that only had 2, 4, and 9 unique values. This might make sense for ordinal or categorical variables. In this case, the dataset only contains numerical variables. As such, only having 2, 4, or 9 unique numerical values in a column might be surprising.\n",
    "\n",
    "### We can refer to these columns or predictors as near-zero variance predictors, as their variance is not zero, but a very small number close to zero.\n",
    "\n",
    "### These columns may or may not contribute to the skill of a model. We can’t assume that they are useless to modeling.\n",
    "\n",
    "### Depending on the choice of data preparation and modeling algorithms, variables with very few numerical values can also cause errors or unexpected results. For example, these can cause errors when using power transforms for data preparation and when fitting linear models that assume a “sensible” data probability distribution.\n",
    "\n",
    "### To help highlight columns of this type, you can calculate the number of unique values for each variable as a percentage of the total number of rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset in array form\n",
    "df = pd.read_csv('oil-spill.csv', header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively\n",
    "# Importing dataset in array form\n",
    "#df = np.loadtxt('oil-spill.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 238, 25.4%\n",
      "1, 297, 31.7%\n",
      "2, 927, 98.9%\n",
      "3, 933, 99.6%\n",
      "4, 179, 19.1%\n",
      "5, 375, 40.0%\n",
      "6, 820, 87.5%\n",
      "7, 618, 66.0%\n",
      "8, 561, 59.9%\n",
      "9, 57, 6.1%\n",
      "10, 577, 61.6%\n",
      "11, 59, 6.3%\n",
      "12, 73, 7.8%\n",
      "13, 107, 11.4%\n",
      "14, 53, 5.7%\n",
      "15, 91, 9.7%\n",
      "16, 893, 95.3%\n",
      "17, 810, 86.4%\n",
      "18, 170, 18.1%\n",
      "19, 53, 5.7%\n",
      "20, 68, 7.3%\n",
      "21, 9, 1.0%\n",
      "22, 1, 0.1%\n",
      "23, 92, 9.8%\n",
      "24, 9, 1.0%\n",
      "25, 8, 0.9%\n",
      "26, 9, 1.0%\n",
      "27, 308, 32.9%\n",
      "28, 447, 47.7%\n",
      "29, 392, 41.8%\n",
      "30, 107, 11.4%\n",
      "31, 42, 4.5%\n",
      "32, 4, 0.4%\n",
      "33, 45, 4.8%\n",
      "34, 141, 15.0%\n",
      "35, 110, 11.7%\n",
      "36, 3, 0.3%\n",
      "37, 758, 80.9%\n",
      "38, 9, 1.0%\n",
      "39, 9, 1.0%\n",
      "40, 388, 41.4%\n",
      "41, 220, 23.5%\n",
      "42, 644, 68.7%\n",
      "43, 649, 69.3%\n",
      "44, 499, 53.3%\n",
      "45, 2, 0.2%\n",
      "46, 937, 100.0%\n",
      "47, 169, 18.0%\n",
      "48, 286, 30.5%\n",
      "49, 2, 0.2%\n"
     ]
    }
   ],
   "source": [
    "# summarize the number of unique values in each column\n",
    "for i in range(df.shape[1]):\n",
    "    num = len(np.unique(df[:, i]))\n",
    "    percentage = float(num) / df.shape[0] * 100\n",
    "    print('%d, %d, %.1f%%' % (i, num, percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can update the example to only summarize those variables that have unique values that are less than 1 percent of the number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21, 9, 1.0%\n",
      "22, 1, 0.1%\n",
      "24, 9, 1.0%\n",
      "25, 8, 0.9%\n",
      "26, 9, 1.0%\n",
      "32, 4, 0.4%\n",
      "36, 3, 0.3%\n",
      "38, 9, 1.0%\n",
      "39, 9, 1.0%\n",
      "45, 2, 0.2%\n",
      "49, 2, 0.2%\n"
     ]
    }
   ],
   "source": [
    "for i in range(df.shape[1]):\n",
    "    num = len(np.unique(df[:, i]))\n",
    "    percentage = float(num) / df.shape[0] * 100\n",
    "    if percentage < 1:\n",
    "        print('%d, %d, %.1f%%' % (i, num, percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the example, we can see that 11 of the 50 variables have numerical variables that have unique values that are less than 1 percent of the number of rows.\n",
    "\n",
    "### This does not mean that these rows and columns should be deleted, but they require further attention.\n",
    "\n",
    "### For example:\n",
    "\n",
    "### Perhaps the unique values can be encoded as ordinal values?\n",
    "### Perhaps the unique values can be encoded as categorical values?\n",
    "### Perhaps compare model skill with each variable removed from the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However, if we wanted to delete all 11 columns with unique values less than 1 percent of rows; the example below demonstrates this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 50)\n"
     ]
    }
   ],
   "source": [
    "# Importing dataset as a dataframe\n",
    "df1 = pd.read_csv('oil-spill.csv', header=None)\n",
    "print(df1.shape)\n",
    "# get number of unique values for each column\n",
    "counts = df1.nunique()\n",
    "# record columns to delete\n",
    "to_del = [i for i, v in enumerate(counts) if float(v)/df.shape[0]*100 < 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 39)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop useless columns\n",
    "df2 = df1.drop(to_del, axis=1)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the example first loads the dataset and reports the number of rows and columns.\n",
    "\n",
    "### The number of unique values for each column is calculated, and those columns that have a number of unique values less than 1 percent of the rows are identified. In this case, 11 columns.\n",
    "\n",
    "### The identified columns are then removed from the DataFrame, and the number of rows and columns in the DataFrame are reported to confirm the change."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd275371c28e8315e03adf8b037f110cb1b8ea1df403d06bca1b2c33c8fa2b88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
